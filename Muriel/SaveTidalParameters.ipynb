{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to save the tidal parameters calculated from the model output to a csv file in order to avoid having to load all the files run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.patches import Ellipse\n",
    "import numpy as np\n",
    "from IPython.display import display, Math, Latex\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import netCDF4 as nc\n",
    "from scipy.optimize import curve_fit\n",
    "from salishsea_tools import (viz_tools,tidetools, nc_tools)\n",
    "from salishsea_tools.nowcast import (research_VENUS, analyze)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hourly Data\n",
    "##@ VENUS nodes\n",
    "The functions below will facilitate loading the hourly data and writting the tidal parameters to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadparam_h(to,tf):\n",
    "    filesu=analyze.get_filenames(to,tf, '1h', 'grid_U', path)\n",
    "    filesv=analyze.get_filenames(to,tf,'1h', 'grid_V', path)\n",
    "\n",
    "    sites=research_VENUS.SITES\n",
    "    i_c=sites['VENUS']['Central']['i']\n",
    "    i_e=sites['VENUS']['East']['i']\n",
    "    j_c=sites['VENUS']['Central']['j']\n",
    "    j_e=sites['VENUS']['East']['j']\n",
    "\n",
    "    u_u_c, time = analyze.combine_files(filesu, 'vozocrtx','None',[j_c-1, j_c], [i_c-1,i_c])\n",
    "    v_v_c, timec = analyze.combine_files(filesv, 'vomecrty','None',[j_c-1, j_c], [i_c-1,i_c])\n",
    "    time_c = tidetools.convert_to_seconds(timec)\n",
    "    dep_t_c = nc.Dataset(filesv[-1]).variables['depthv']\n",
    "\n",
    "    u_u_e, time = analyze.combine_files(filesu, 'vozocrtx','None',[j_e-1, j_e], [i_e-1,i_e])\n",
    "    v_v_e, timee = analyze.combine_files(filesv, 'vomecrty','None',[j_e-1, j_e], [i_e-1,i_e])\n",
    "    time_e = tidetools.convert_to_seconds(timee)\n",
    "    dep_t_e = nc.Dataset(filesv[-1]).variables['depthv']\n",
    "    \n",
    "    depth=[dep_t_c[:], dep_t_e[:]] \n",
    "    \n",
    "    u_u_0 = np.ma.masked_values(u_u_e, 0)\n",
    "    v_v_0 = np.ma.masked_values(v_v_e, 0)\n",
    "    u_u_0c = np.ma.masked_values(u_u_c, 0)\n",
    "    v_v_0c = np.ma.masked_values(v_v_c, 0)\n",
    "\n",
    "    u_c, v_c=research_VENUS.unstag_rot_gridded(u_u_0c, v_v_0c, 'Central')\n",
    "    u_e, v_e=research_VENUS.unstag_rot_gridded(u_u_0, v_v_0, 'East')\n",
    "    times=[time_c,time_e]\n",
    "    us=[u_c, u_e]\n",
    "    vs=[v_c, v_e]\n",
    "    i=np.arange(0,2)\n",
    "\n",
    "    thesize=(40,2)\n",
    "    vM2amp = np.zeros(thesize); vM2pha = np.zeros(thesize)\n",
    "    vK1amp = np.zeros(thesize); vK1pha = np.zeros(thesize)\n",
    "    uM2amp = np.zeros(thesize); uM2pha = np.zeros(thesize)\n",
    "    uK1amp = np.zeros(thesize); uK1pha = np.zeros(thesize)\n",
    "\n",
    "    for i, u, time, v in zip(i, us, times, vs):\n",
    "        uM2amp[:,i], uM2pha[:,i], uK1amp[:,i], uK1pha[:,i] = tidetools.fittit(u, time)\n",
    "        vM2amp[:,i], vM2pha[:,i], vK1amp[:,i], vK1pha[:,i] = tidetools.fittit(v, time) \n",
    "\n",
    "    CX, SX, CY, SY, ap, am, ep, em, major, minor, theta = tidetools.ellipse_params (uM2amp, uM2pha, vM2amp, vM2pha)\n",
    "    CX_k, SX_k, CY_k, SY_k, ap_k, am_k, ep_k, em_k, major_k, minor_k, theta_k = tidetools.ellipse_params (uK1amp, uK1pha, vK1amp, vK1pha)\n",
    "    return depth, major, minor, theta, major_k, minor_k, theta_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filenames(t_orig, t_final, station, model_path):\n",
    "    \"\"\"Returns a list with the filenames for all files over the\n",
    "    defined period of time and sorted in chronological order.\n",
    "\n",
    "    :arg t_orig: The beginning of the date range of interest.\n",
    "    :type t_orig: datetime object\n",
    "\n",
    "    :arg t_final: The end of the date range of interest.\n",
    "    :type t_final: datetime object\n",
    "\n",
    "    :arg period: Time interval of model results (eg. 1h or 1d).\n",
    "    :type period: string\n",
    "\n",
    "    :arg grid: Type of model results (eg. grid_T, grid_U, etc).\n",
    "    :type grid: string\n",
    "\n",
    "    :arg model_path: Defines the path used (eg. nowcast)\n",
    "    :type model_path: string\n",
    "\n",
    "    :returns: files, a list of filenames\n",
    "    \"\"\"\n",
    "\n",
    "    numdays = (t_final-t_orig).days\n",
    "    dates = [t_orig + datetime.timedelta(days=num)\n",
    "             for num in range(0, numdays+1)]\n",
    "    dates.sort()\n",
    "    \n",
    "    allfiles = glob.glob(model_path+'/*/VENUS_*_gridded.nc')\n",
    "    sdt = dates[0].strftime('%d%b%y')\n",
    "    edt = dates[-1].strftime('%d%b%y')\n",
    "    \n",
    "    sdt = sdt.lower()\n",
    "    edt = edt.lower()\n",
    "    \n",
    "    sstr = '/{}/VENUS_{}_gridded.nc'.format(sdt, station)\n",
    "    estr = '/{}/VENUS_{}_gridded.nc'.format(edt, station)\n",
    "    print estr\n",
    "    files = []\n",
    "    for filename in allfiles:\n",
    "        if os.path.basename(filename) >= sstr:\n",
    "            if os.path.basename(filename) <= estr:\n",
    "                files.append(filename)\n",
    "\n",
    "    files.sort(key=os.path.basename)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/11may15/VENUS_east_gridded.nc\n",
      "/11may15/VENUS_central_gridded.nc\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast'\n",
    "to=datetime.datetime(2015,5,9)\n",
    "tf=datetime.datetime(2015,5,11)\n",
    "\n",
    "filesu=get_filenames(to,tf, 'east', path)\n",
    "filesv=get_filenames(to,tf,'central', path)\n",
    "print filesu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadparam_15(to, tf):\n",
    "    files = []\n",
    "    files_East = glob.glob(os.path.join(path,'*','VENUS_east_gridded.nc'))\n",
    "    for f in files_East:\n",
    "        directory=os.path.dirname(f)\n",
    "        files.append(glob.glob(os.path.join(directory,'*_1h_*_grid_T*'))[0])\n",
    "    files.sort(key=os.path.basename)\n",
    "\n",
    "    files_East = [];\n",
    "    files_Central=[];\n",
    "    for f in files:\n",
    "        directory=os.path.dirname(f)\n",
    "        files_East.append(os.path.join(directory,'VENUS_east_gridded.nc'))\n",
    "        files_Central.append(os.path.join(directory,'VENUS_central_gridded.nc'))\n",
    "    \n",
    "    u_u_c, timer = analyze.combine_files(files_Central, 'vozocrtx','None',[0,1], [0,1])\n",
    "    v_v_c, time = analyze.combine_files(files_Central, 'vomecrty','None', [0,1], [0,1])\n",
    "    time_c = tidetools.convert_to_seconds(timer)\n",
    "    dep_t_c, time = combine_t(files_Central, 'depthv')\n",
    "\n",
    "    u_u_e, time = analyze.combine_files(files_East,'vozocrtx', 'None', [0,1], [0,1])\n",
    "    v_v_e, time = analyze.combine_files(files_East,'vomecrty', 'None',[0,1], [0,1])\n",
    "    time_e, time = tidetools.convert_to_seconds(timer)\n",
    "    dep_t_e, time = combine_t(files_East, 'depthv')\n",
    "    \n",
    "    depth=[dep_t_c[:], dep_t_e[:]] \n",
    "    \n",
    "    u_u_0 = np.ma.masked_values(u_u_e, 0)\n",
    "    v_v_0 = np.ma.masked_values(v_v_e, 0)\n",
    "    u_u_0c = np.ma.masked_values(u_u_c, 0)\n",
    "    v_v_0c = np.ma.masked_values(v_v_c, 0)\n",
    "\n",
    "    u_c, v_c=research_VENUS.unstag_rot_gridded(u_u_0c, v_v_0c, 'Central')\n",
    "    u_e, v_e=research_VENUS.unstag_rot_gridded(u_u_0, v_v_0, 'East')\n",
    "    times=[time_c,time_e]\n",
    "    us=[u_c, u_e]\n",
    "    vs=[v_c, v_e]\n",
    "    i=np.arange(0,2)\n",
    "\n",
    "    thesize=(40,2)\n",
    "    vM2amp = np.zeros(thesize); vM2pha = np.zeros(thesize)\n",
    "    vK1amp = np.zeros(thesize); vK1pha = np.zeros(thesize)\n",
    "    uM2amp = np.zeros(thesize); uM2pha = np.zeros(thesize)\n",
    "    uK1amp = np.zeros(thesize); uK1pha = np.zeros(thesize)\n",
    "\n",
    "    for i, u, time, v in zip(i, us, times, vs):\n",
    "        uM2amp[:,i], uM2pha[:,i], uK1amp[:,i], uK1pha[:,i] = tidetools.fittit(u, time)\n",
    "        vM2amp[:,i], vM2pha[:,i], vK1amp[:,i], vK1pha[:,i] = tidetools.fittit(v, time) \n",
    "\n",
    "    CX, SX, CY, SY, ap, am, ep, em, major, minor, theta = tidetools.ellipse_params (uM2amp, uM2pha, vM2amp, vM2pha)\n",
    "    CX_k, SX_k, CY_k, SY_k, ap_k, am_k, ep_k, em_k, major_k, minor_k, theta_k = tidetools.ellipse_params (uK1amp, uK1pha, vK1amp, vK1pha)\n",
    "    return depth, major, minor, theta, major_k, minor_k, theta_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to save tidal parameters in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writetocsv(runname, depth, major, minor,theta, majork1, minork1, thetak1, station):\n",
    "    outfile = runname+'.csv'\n",
    "    \n",
    "    if station == 'Central':\n",
    "        k=0\n",
    "    else:\n",
    "        k=1\n",
    "    \n",
    "    with open(outfile, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow([\n",
    "                'Depth', 'Major-Axis (M2)', 'Minor-Axis (M2)', 'Theta (M2)',\n",
    "                'Major-Axis (K1)', 'Minor-Axis (K1)', 'Theta (K1)'\n",
    "            ])\n",
    "        for i in np.arange(0,39):\n",
    "            writer.writerow([depth[k][i], major[i,k], minor[i,k], theta[i,k], majork1[i,k], minork1[i,k], thetak1[i,k]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###All the hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast.nc'\n",
    "to=datetime.datetime(2014,11,1)\n",
    "tf=datetime.datetime(2015,6,8)\n",
    "\n",
    "depth, major, minor, theta, major_k, minor_k, theta_k= loadparam_h(to,tf)\n",
    "\n",
    "runname = '20141101_20150608_h_Central'\n",
    "runnamee = '20141101_20150608_h_East'\n",
    "\n",
    "writetocsv(runname, depth, major, minor, theta, major_k, minor_k, theta_k, 'Central')\n",
    "writetocsv(runnamee, depth, major, minor, theta, major_k, minor_k, theta_k, 'East')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to open and read the columns you could use the lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('20150601_20150608_h_Central.csv')\n",
    "depth = df.Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Month of May 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to=datetime.datetime(2015,5,1)\n",
    "tf=datetime.datetime(2015,5,30)\n",
    "\n",
    "depth, major, minor, theta, major_k, minor_k, theta_k= loadparam_h(to,tf)\n",
    "runname1 = '20150501_20150530_h_Central'\n",
    "runname2 = '20150501_20150530_h_East'\n",
    "\n",
    "writetocsv(runname1, depth, major, minor, theta, major_k, minor_k, theta_k, 'Central')\n",
    "writetocsv(runname2, depth, major, minor, theta, major_k, minor_k, theta_k, 'East')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
