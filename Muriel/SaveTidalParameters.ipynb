{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to save the tidal parameters calculated from the model output to a csv file in order to avoid having to load all the files run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.patches import Ellipse\n",
    "import numpy as np\n",
    "from IPython.display import display, Math, Latex\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import netCDF4 as nc\n",
    "from scipy.optimize import curve_fit\n",
    "from salishsea_tools import (viz_tools,tidetools, nc_tools)\n",
    "from salishsea_tools.nowcast import (research_VENUS, analyze)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hourly Data\n",
    "##@ VENUS nodes\n",
    "The functions below will facilitate loading the hourly data and writting the tidal parameters to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadparam(to, tf, path, freq='h', depav='None'):\n",
    "    \"\"\" This function loads all the data between the start and the end date\n",
    "    that contains hourly velocity netCDF4 files. Then it mask, unstaggers and \n",
    "    rotates the velocities by component about the VENUS nodes. Lastly it fits \n",
    "    the velcities and caculates the tidal ellipse parameters for that date range.\n",
    "    \n",
    "    depth : vector [dmin, dmax]\n",
    "    \"\"\"\n",
    "    if freq=='h':\n",
    "        filesu = analyze.get_filenames(to,tf, '1h', 'grid_U', path)\n",
    "        filesv=analyze.get_filenames(to,tf,'1h', 'grid_V', path)\n",
    "\n",
    "        sites=research_VENUS.SITES\n",
    "        i_c=sites['VENUS']['Central']['i']\n",
    "        i_e=sites['VENUS']['East']['i']\n",
    "        j_c=sites['VENUS']['Central']['j']\n",
    "        j_e=sites['VENUS']['East']['j']\n",
    "        \n",
    "        a = filesu\n",
    "        b = filesv\n",
    "        c = filesu\n",
    "        d = filesv\n",
    "        \n",
    "    else:\n",
    "        files_Central=analyze.get_filenames_15(to,tf, 'central', path)\n",
    "        files_East=analyze.get_filenames_15(to,tf,'east', path)\n",
    "        \n",
    "        i_c = 1\n",
    "        i_e = 1\n",
    "        j_c = 1\n",
    "        j_e = 1\n",
    "        \n",
    "        a = files_Central\n",
    "        b = files_Central\n",
    "        c = files_East\n",
    "        d = files_East\n",
    "\n",
    "    u_u_c, time = analyze.combine_files(a, 'vozocrtx','None',[j_c-1, j_c], [i_c-1,i_c])\n",
    "    v_v_c, timec = analyze.combine_files(b, 'vomecrty','None',[j_c-1, j_c], [i_c-1,i_c])\n",
    "    time_c = tidetools.convert_to_seconds(timec)\n",
    "    dep_t_c = nc.Dataset(b[-1]).variables['depthv']\n",
    "\n",
    "    u_u_e, time = analyze.combine_files(c, 'vozocrtx','None',[j_e-1, j_e], [i_e-1,i_e])\n",
    "    v_v_e, timee = analyze.combine_files(d, 'vomecrty','None',[j_e-1, j_e], [i_e-1,i_e])\n",
    "    time_e = tidetools.convert_to_seconds(timee)\n",
    "    dep_t_e = nc.Dataset(d[-1]).variables['depthv']\n",
    "\n",
    "        \n",
    "    depth=[dep_t_c[:], dep_t_e[:]] \n",
    "    \n",
    "    u_u_0 = np.ma.masked_values(u_u_e, 0)\n",
    "    v_v_0 = np.ma.masked_values(v_v_e, 0)\n",
    "    u_u_0c = np.ma.masked_values(u_u_c, 0)\n",
    "    v_v_0c = np.ma.masked_values(v_v_c, 0)\n",
    "\n",
    "    u_c, v_c=research_VENUS.unstag_rot_gridded(u_u_0c, v_v_0c, 'Central')\n",
    "    u_e, v_e=research_VENUS.unstag_rot_gridded(u_u_0, v_v_0, 'East')\n",
    "\n",
    "    \n",
    "    \n",
    "    if depav == 'None':\n",
    "        us=[u_c, u_e]\n",
    "        vs=[v_c, v_e]   \n",
    "        thesize=(40,2)\n",
    "        \n",
    "    else: \n",
    "        jc = np.where(np.logical_and( depth[0] > depav[0], depth[0] < depav[1]))\n",
    "        je = np.where(np.logical_and( depth[1] > depav[2], depth[1] < depav[3]))\n",
    "        \n",
    "        u_c_slice = u_c[:,jc[0]]\n",
    "        v_c_slice = v_c[:,jc[0]]\n",
    "        u_e_slice = u_e[:,je[0]]\n",
    "        v_e_slice = v_e[:,je[0]]\n",
    "        \n",
    "        uc_av = analyze.depth_average(u_c_slice,depth[0][jc],1)\n",
    "        vc_av = analyze.depth_average(v_c_slice,depth[0][jc],1)\n",
    "        ue_av = analyze.depth_average(u_e_slice,depth[1][je],1)\n",
    "        ve_av = analyze.depth_average(v_e_slice,depth[1][je],1)\n",
    "        \n",
    "        thesize = (1,2)\n",
    "        us=[uc_av, ue_av]\n",
    "        vs=[vc_av, ve_av] \n",
    "        \n",
    "    times=[time_c,time_e]    \n",
    "    i=np.arange(0,2)\n",
    "\n",
    "    vM2amp = np.zeros(thesize); vM2pha = np.zeros(thesize)\n",
    "    vK1amp = np.zeros(thesize); vK1pha = np.zeros(thesize)\n",
    "    uM2amp = np.zeros(thesize); uM2pha = np.zeros(thesize)\n",
    "    uK1amp = np.zeros(thesize); uK1pha = np.zeros(thesize) \n",
    "    for i, u, time, v in zip(i, us, times, vs):\n",
    "        uM2amp[:,i], uM2pha[:,i], uK1amp[:,i], uK1pha[:,i] = tidetools.fittit(u, time)\n",
    "        vM2amp[:,i], vM2pha[:,i], vK1amp[:,i], vK1pha[:,i] = tidetools.fittit(v, time)\n",
    "\n",
    "    CX, SX, CY, SY, ap, am, ep, em, major, minor, theta, phase = tidetools.ellipse_params (uM2amp, uM2pha, vM2amp, vM2pha)\n",
    "    CX_k, SX_k, CY_k, SY_k, ap_k, am_k, ep_k, em_k, major_k, minor_k, theta_k, phase_k = tidetools.ellipse_params (uK1amp, uK1pha, vK1amp, vK1pha)\n",
    "\n",
    "    return depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2015,6,6)\n",
    "tf=datetime.datetime(2015,6,8)\n",
    "freq = 'h'\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam(to, tf, path, 'h', depav=[35,300,20,160])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filenames_15(t_orig, t_final, station, model_path):\n",
    "    \"\"\"Returns a list with the filenames for all files over the\n",
    "    defined period of time and sorted in chronological order for \n",
    "    the gridded 15 minutes data.\n",
    "\n",
    "    :arg t_orig: The beginning of the date range of interest.\n",
    "    :type t_orig: datetime object\n",
    "\n",
    "    :arg t_final: The end of the date range of interest.\n",
    "    :type t_final: datetime object\n",
    "\n",
    "    :arg model_path: Defines the path used (eg. nowcast)\n",
    "    :type model_path: string\n",
    "\n",
    "    :returns: files, a list of filenames\n",
    "    \"\"\"\n",
    "\n",
    "    numdays = (t_final-t_orig).days\n",
    "    dates = [t_orig + datetime.timedelta(days=num)\n",
    "             for num in range(0, numdays+1)]\n",
    "    dates.sort()\n",
    "    \n",
    "    files = []\n",
    "    for i in dates:\n",
    "        sdt = i.strftime('%d%b%y').lower()\n",
    "        filename = (model_path+'{}/VENUS_{}_gridded.nc'.format(sdt, station))\n",
    "        files.append(filename)\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadparam_15(to, tf, path):\n",
    "    \"\"\" This function loads all the data between the start and the end date\n",
    "    that contains gridded quarter-hourly velocity netCDF4 files. Then it mask, unstaggers and \n",
    "    rotates the velocities by component about the VENUS nodes. Lastly it fits \n",
    "    the velcities and caculates the tidal ellipse parameters for that date range.**(Important not \n",
    "    to have a to < 2015-05-09 because the files do not exist before this date).**\n",
    "    \"\"\"\n",
    "    \n",
    "    files_Central=analyze.get_filenames_15(to,tf, 'central', path)\n",
    "    files_East=analyze.get_filenames_15(to,tf,'east', path)\n",
    "    \n",
    "    u_u_c, timer = analyze.combine_files(files_Central, 'vozocrtx','None',[0,1], [0,1])\n",
    "    v_v_c, time = analyze.combine_files(files_Central, 'vomecrty','None', [0,1], [0,1])\n",
    "    time_c = tidetools.convert_to_seconds(timer)\n",
    "    dep_t_c= nc.Dataset(files_Central[-1]).variables['depthv']\n",
    "\n",
    "    u_u_e, time = analyze.combine_files(files_East,'vozocrtx', 'None', [0,1], [0,1])\n",
    "    v_v_e, time = analyze.combine_files(files_East,'vomecrty', 'None',[0,1], [0,1])\n",
    "    time_e = tidetools.convert_to_seconds(timer)\n",
    "    dep_t_e = nc.Dataset(files_East[-1]).variables['depthv']\n",
    "    \n",
    "    depth=[dep_t_c[:], dep_t_e[:]] \n",
    "    \n",
    "    u_u_0 = np.ma.masked_values(u_u_e, 0)\n",
    "    v_v_0 = np.ma.masked_values(v_v_e, 0)\n",
    "    u_u_0c = np.ma.masked_values(u_u_c, 0)\n",
    "    v_v_0c = np.ma.masked_values(v_v_c, 0)\n",
    "\n",
    "    u_c, v_c=research_VENUS.unstag_rot_gridded(u_u_0c, v_v_0c, 'Central')\n",
    "    u_e, v_e=research_VENUS.unstag_rot_gridded(u_u_0, v_v_0, 'East')\n",
    "    times=[time_c,time_e]\n",
    "    us=[u_c, u_e]\n",
    "    vs=[v_c, v_e]\n",
    "    i=np.arange(0,2)\n",
    "\n",
    "    thesize=(40,2)\n",
    "    vM2amp = np.zeros(thesize); vM2pha = np.zeros(thesize)\n",
    "    vK1amp = np.zeros(thesize); vK1pha = np.zeros(thesize)\n",
    "    uM2amp = np.zeros(thesize); uM2pha = np.zeros(thesize)\n",
    "    uK1amp = np.zeros(thesize); uK1pha = np.zeros(thesize)\n",
    "\n",
    "    for i, u, time, v in zip(i, us, times, vs):\n",
    "        uM2amp[:,i], uM2pha[:,i], uK1amp[:,i], uK1pha[\n",
    "            :,i] = tidetools.fittit(u, time)\n",
    "        vM2amp[:,i], vM2pha[:,i], vK1amp[:,i], vK1pha[\n",
    "            :,i] = tidetools.fittit(v, time) \n",
    "\n",
    "    CX, SX, CY, SY, ap, am, ep, em, major, minor, theta = tidetools.ellipse_params (uM2amp, uM2pha, vM2amp, vM2pha)\n",
    "   \n",
    "    CX_k, SX_k, CY_k, SY_k, ap_k, am_k, ep_k, em_k, major_k, minor_k, theta_k = tidetools.ellipse_params (uK1amp, uK1pha, vK1amp, vK1pha)\n",
    "    return depth, major, minor, theta, major_k, minor_k, theta_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to save tidal parameters in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writetocsv(runname, depth, major, minor,theta, phase, majork1, minork1, thetak1, phasek1, station):\n",
    "    outfile = runname+'.csv'\n",
    "    \n",
    "    if station == 'Central':\n",
    "        k=0\n",
    "        with open(outfile, 'wb') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerow([\n",
    "                'Depth', 'Major(M2)', 'Minor(M2)', 'Inc(M2)','Pha(M2)',\n",
    "                'Major(K1)', 'Minor(K1)', 'Inc(K1)', 'Pha(K1)'\n",
    "            ])\n",
    "            for i in np.arange(0,39):\n",
    "                writer.writerow([depth[k][i], major[i,k], minor[i,k], theta[i,k], phase[i,k], majork1[i,k], minork1[i,k], thetak1[i,k], phasek1[i,k]])\n",
    "\n",
    "    elif station == 'East':\n",
    "        k=1\n",
    "        with open(outfile, 'wb') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerow([\n",
    "                'Depth', 'Major(M2)', 'Minor(M2)', 'Inc(M2)','Pha(M2)',\n",
    "                'Major(K1)', 'Minor(K1)', 'Inc(K1)', 'Pha(K1)'\n",
    "            ])\n",
    "            for i in np.arange(0,39):\n",
    "                writer.writerow([depth[k][i], major[i,k], minor[i,k], theta[i,k], phase[i,k], majork1[i,k], minork1[i,k], thetak1[i,k], phasek1[i,k]])\n",
    "\n",
    "    elif major.shape[0] == 40:\n",
    "        with open(outfile, 'wb') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerow([\n",
    "                'Depth', 'Major(M2)', 'Minor(M2)', 'Inc(M2)','Pha(M2)',\n",
    "                'Major(K1)', 'Minor(K1)', 'Inc(K1)', 'Pha(K1)'\n",
    "            ])\n",
    "            for i in np.arange(0,39):\n",
    "                writer.writerow([depth[i], major[i], minor[i], theta[i], phase[i], majork1[i], minork1[i], thetak1[i], phasek1[i]])\n",
    "\n",
    "    else:\n",
    "        k=0\n",
    "        with open(outfile, 'wb') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',')\n",
    "            writer.writerow([\n",
    "                'Major(M2)', 'Minor(M2)', 'Inc(M2)','Pha(M2)',\n",
    "                'Major(K1)', 'Minor(K1)', 'Inc(K1)', 'Pha(K1)'\n",
    "            ])\n",
    "            mat = (major[0], minor[0], theta[0], phase[0], majork1[0], minork1[0], thetak1[0], phasek1[0])\n",
    "            writer.writerow(mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###All the hourly data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not use data before November 26th 2014 for tidal ellipses, the model tides change this day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2014,11,26)\n",
    "tf=datetime.datetime(2015,6,27)\n",
    "freq = '15'\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "depav = [35,300,20,160]\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k = research_VENUS.loadparam_all(to, tf, path, 266, 424, depav=[35,300])\n",
    "runname1 = '{}_{}_{}_Central_depav'.format(t_o, t_f, freq)\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k,'Mone')\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k = research_VENUS.loadparam_all(to, tf, path, 283, 416, depav=[20,160])\n",
    "runname2 = '{}_{}_{}_East_depav'.format(t_o, t_f, freq)\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k,'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Seasonal sensitivity\n",
    "Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2014,11,26)\n",
    "tf=datetime.datetime(2015,2,26)\n",
    "freq = 'h'\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k = research_VENUS.loadparam_all(to, tf,path, 266, 424 )\n",
    "runname1 = '{}_{}_Central_winter'.format(t_o, t_f)\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k = research_VENUS.loadparam_all(to, tf, path, 283, 416)\n",
    "runname2 = '{}_{}_East_winter'.format(t_o, t_f)\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2015,2,27)\n",
    "tf=datetime.datetime(2015,5,27)\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k = research_VENUS.loadparam_all(to, tf,path, 266, 424)\n",
    "runname1 = '{}_{}_Central_spring'.format(t_o, t_f)\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k = research_VENUS.loadparam_all(to, tf, path, 283, 416)\n",
    "runname2 = '{}_{}_East_spring'.format(t_o, t_f)\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###For all quarter-hourly values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2015,5,9)\n",
    "tf=datetime.datetime(2015,6,9)\n",
    "freq= 'h'\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= loadparam(to, tf, path)\n",
    "runname1 = '{}_{}_{}_Central'.format(t_o, t_f, freq)\n",
    "runname2 = '{}_{}_{}_East'.format(t_o, t_f, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'Central')\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'East')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to open and read the columns you could use the lines below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df = pd.read_csv('20150601_20150608_h_Central.csv')\n",
    "depth = df.Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Quarter-Hourly Data\n",
    "##@ VENUS nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Month of May 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gridded data quarter hourly data only started to be recorded on May 9th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2014,11,26)\n",
    "tf=datetime.datetime(2015,6,26)\n",
    "freq='h'\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k=loadparam(to, tf, path)\n",
    "runname1 = '{}_{}_{}_Central'.format(t_o, t_f, freq)\n",
    "runname2 = '{}_{}_{}_East'.format(t_o, t_f, freq)\n",
    "\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'Central')\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'East')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Hourly Data at Other Locations\n",
    "##Foreman Model Locations\n",
    "In Foreman et al. (2004) the tidal currents amplitude and phase of their model was compared to observations at 7 locations. For the locations that are contained in the model I will make comparisons with these values. I this notebook I will load the data. See [notebook](http://nbviewer.ipython.org/urls/bitbucket.org/salishsea/analysis/raw/tip/Muriel/TidalEllipsesComparisons.ipynb) for comparison. The locations and numbers are from Foreman et al. (2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadparam_all(to, tf, path, i, j, depav='None'):\n",
    "    \"\"\" This function loads all the data between the start and the end date\n",
    "    that contains hourly velocity netCDF4 files. Then it mask, unstaggers and \n",
    "    rotates the velocities by component about the VENUS nodes. Lastly it fits \n",
    "    the velcities and caculates the tidal ellipse parameters for that date range.\n",
    "    \n",
    "    depth : vector [dmin, dmax]\n",
    "    \"\"\"\n",
    "\n",
    "    filesu = analyze.get_filenames(to,tf, '1h', 'grid_U', path)\n",
    "    filesv=analyze.get_filenames(to,tf,'1h', 'grid_V', path)\n",
    "\n",
    "    u_u, timer = analyze.combine_files(filesu, 'vozocrtx','None',[j-1, j], [i-1,i])\n",
    "    v_v, time = analyze.combine_files(filesv, 'vomecrty','None',[j-1, j], [i-1,i])\n",
    "    time = tidetools.convert_to_seconds(timer)\n",
    "    print time\n",
    "    \n",
    "    dep_t = nc.Dataset(filesu[-1]).variables['depthu'];\n",
    "    \n",
    "    u_u_0 = np.ma.masked_values(u_u, 0)\n",
    "    v_v_0 = np.ma.masked_values(v_v, 0)\n",
    "\n",
    "    u, v=research_VENUS.unstag_rot(u_u_0, v_v_0, 1 , 1)\n",
    "   \n",
    "    if depav == 'None':  \n",
    "        thesize=(40)\n",
    "        \n",
    "    else: \n",
    "        j = np.where(np.logical_and(dep_t[:] > depav[0], dep_t[:] < depav[1]))\n",
    "\n",
    "        u_slice = u[:,j[0]]\n",
    "        v_slice = v[:,j[0]]\n",
    "        u = analyze.depth_average(u_slice, dep_t[j], 1)\n",
    "        v = analyze.depth_average(v_slice, dep_t[j], 1)\n",
    "        \n",
    "        thesize = (1)\n",
    "           \n",
    "    vM2amp = np.zeros(thesize); vM2pha = np.zeros(thesize)\n",
    "    vK1amp = np.zeros(thesize); vK1pha = np.zeros(thesize)\n",
    "    uM2amp = np.zeros(thesize); uM2pha = np.zeros(thesize)\n",
    "    uK1amp = np.zeros(thesize); uK1pha = np.zeros(thesize) \n",
    "    uM2amp[:], uM2pha[:], uK1amp[:], uK1pha[:] = tidetools.fittit(u, time)\n",
    "    vM2amp[:], vM2pha[:], vK1amp[:], vK1pha[:] = tidetools.fittit(v, time)\n",
    "\n",
    "    CX, SX, CY, SY, ap, am, ep, em, major, minor, theta, phase = tidetools.ellipse_params (uM2amp, uM2pha, vM2amp, vM2pha)\n",
    "    CX_k, SX_k, CY_k, SY_k, ap_k, am_k, ep_k, em_k, major_k, minor_k, theta_k, phase_k = tidetools.ellipse_params (uK1amp, uK1pha, vK1amp, vK1pha)\n",
    "\n",
    "    return dep_t, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###35 - Haro Strait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 312\n"
     ]
    }
   ],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "lon35 = -123.225789\n",
    "lat35 = 48.537579\n",
    "\n",
    "grid_B = nc.Dataset('/data/dlatorne/MEOPAR/NEMO-forcing/grid/bathy_meter_SalishSea2.nc')\n",
    "bathy, X, Y = tidetools.get_bathy_data(grid_B)\n",
    "j35, i35 = tidetools.find_closest_model_point(lon35, lat35, X, Y, bathy)\n",
    "print i35, j35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to=datetime.datetime(2014, 11, 26)\n",
    "tf=datetime.datetime(2015, 6, 29)\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "depav = [35,300,20,160]\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i35, j35)\n",
    "runname1 = '{}_{}_Haro'.format(t_o, t_f)\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i35, j35, depav=[0, 400])\n",
    "runname2 = '{}_{}_Haro_depav(0-400)'.format(t_o, t_f)\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###33 - Juan de Fuca West"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 408\n"
     ]
    }
   ],
   "source": [
    "lat33 = 48.483\n",
    "lon33 = -124.713\n",
    "\n",
    "j33, i33 = tidetools.find_closest_model_point(lon33, lat33, X, Y, bathy)\n",
    "print i33, j33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to=datetime.datetime(2014, 11, 26)\n",
    "tf=datetime.datetime(2015, 6, 29)\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i33, j33)\n",
    "runname1 = '{}_{}_JuanW'.format(t_o, t_f)\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i33, j33, depav=[0, 400])\n",
    "runname2 = '{}_{}_JuanW_depav(0-400)'.format(t_o, t_f)\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###34 - Juan de Fuca East"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 275\n"
     ]
    }
   ],
   "source": [
    "lat34 = 48.232\n",
    "lon34 = -123.530\n",
    "\n",
    "j34, i34 = tidetools.find_closest_model_point(lon34, lat34, X, Y, bathy)\n",
    "print i34, j34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to=datetime.datetime(2014, 11, 26)\n",
    "tf=datetime.datetime(2015, 6, 29)\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i34, j34)\n",
    "runname1 = '{}_{}_JuanE'.format(t_o, t_f)\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i34, j34, depav=[0, 400])\n",
    "runname2 = '{}_{}_JuanE_depav(0-400)'.format(t_o, t_f)\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###36 - Seymour Narrows\n",
    "Seymour Narrows is too narrow. Therefore we encounter problems when unstaggering. The neighbouring cells are masked and this causes problems in the calculation routines. I will choose a slightly different location while trying to maintain similar bathymetry and velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 774 54.25\n"
     ]
    }
   ],
   "source": [
    "lat36 = 50.135820\n",
    "lon36 = -125.353403\n",
    "\n",
    "j36, i36 = tidetools.find_closest_model_point(lon36, lat36, X, Y, bathy)\n",
    "print i36, j36, bathy[j36, i36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inew36=i36-1\n",
    "jnew36=j36-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to=datetime.datetime(2014, 11, 26)\n",
    "tf=datetime.datetime(2015, 6, 29)\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, inew36, jnew36)\n",
    "runname1 = '{}_{}_SN'.format(t_o, t_f)\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k=research_VENUS.loadparam_all(to, tf, path, inew36, jnew36, depav=[0, 400])\n",
    "runname2 = '{}_{}_SN_depav(0-400)'.format(t_o, t_f)\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###38 - Johnstone Strait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 885\n"
     ]
    }
   ],
   "source": [
    "lat38 = 50.454991\n",
    "lon38 = -126.038740\n",
    "\n",
    "j38, i38 = tidetools.find_closest_model_point(lon38,lat38,X, Y, bathy)\n",
    "print i38, j38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to=datetime.datetime(2014, 11, 26)\n",
    "tf=datetime.datetime(2015, 6, 29)\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i38, j38)\n",
    "runname1 = '{}_{}_JS'.format(t_o, t_f)\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i38, j38, depav=[0, 400])\n",
    "runname2 = '{}_{}_JS_depav(0-400)'.format(t_o, t_f)\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###37 - Arran Rapids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 814\n"
     ]
    }
   ],
   "source": [
    "lat37 = 50.416667\n",
    "lon37 = -125.133333\n",
    "j37, i37 = tidetools.find_closest_model_point(lon37,lat37,X, Y, bathy)\n",
    "print i37, j37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inew37 = i37+2\n",
    "jnew37 = j37-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to=datetime.datetime(2014, 11, 26)\n",
    "tf=datetime.datetime(2015, 6, 29)\n",
    "\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, inew37, jnew37)\n",
    "runname1 = '{}_{}_AR'.format(t_o, t_f)\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, inew37, jnew37, depav=[0, 500])\n",
    "runname2 = '{}_{}_AR_depav(0-400)'.format(t_o, t_f)\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Thalweg Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thalweg = np.loadtxt('/data/dlatorne/MEOPAR/tools/bathymetry/thalweg_working.txt', dtype=int, unpack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Systematic choice of Thalweg Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in [800, 900, 1000, 1100, 1200, 1400, 1500]:\n",
    "    i = thalweg[1,k]\n",
    "    j = thalweg[0,k]\n",
    "    depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i, j)\n",
    "    runname1 = '{}_{}_thalweg_{}'.format(t_o, t_f, k)\n",
    "    writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')\n",
    "\n",
    "    depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i, j, depav=[0, 400])\n",
    "    runname2 = '{}_{}_thalweg_{}_depav(0-400)'.format(t_o, t_f, k)\n",
    "    writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Haro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to=datetime.datetime(2014, 11, 26)\n",
    "tf=datetime.datetime(2015, 6, 29)\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "for k in np.arange(480,530,4):\n",
    "    i = thalweg[1,k]\n",
    "    j = thalweg[0,k]\n",
    "    depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i, j)\n",
    "    runname1 = '{}_{}_HaroS_{}'.format(t_o, t_f, k)\n",
    "    writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')\n",
    "\n",
    "    depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= research_VENUS.loadparam_all(to, tf, path, i, j, depav=[0, 400])\n",
    "    runname2 = '{}_{}_HaroS_{}_depav(0-400)'.format(t_o, t_f, k)\n",
    "    writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
