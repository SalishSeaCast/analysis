{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to save the tidal parameters calculated from the model output to a csv file in order to avoid having to load all the files run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.patches import Ellipse\n",
    "import numpy as np\n",
    "from IPython.display import display, Math, Latex\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import netCDF4 as nc\n",
    "from scipy.optimize import curve_fit\n",
    "from salishsea_tools import (viz_tools,tidetools, nc_tools)\n",
    "from salishsea_tools.nowcast import (research_VENUS, analyze)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hourly Data\n",
    "##@ VENUS nodes\n",
    "The functions below will facilitate loading the hourly data and writting the tidal parameters to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadparam(to, tf, path, freq='h'):\n",
    "    \"\"\" This function loads all the data between the start and the end date\n",
    "    that contains hourly velocity netCDF4 files. Then it mask, unstaggers and \n",
    "    rotates the velocities by component about the VENUS nodes. Lastly it fits \n",
    "    the velcities and caculates the tidal ellipse parameters for that date range.\n",
    "    \n",
    "    \"\"\"\n",
    "    if freq=='h':\n",
    "        filesu = analyze.get_filenames(to,tf, '1h', 'grid_U', path)\n",
    "        filesv=analyze.get_filenames(to,tf,'1h', 'grid_V', path)\n",
    "\n",
    "        sites=research_VENUS.SITES\n",
    "        i_c=sites['VENUS']['Central']['i']\n",
    "        i_e=sites['VENUS']['East']['i']\n",
    "        j_c=sites['VENUS']['Central']['j']\n",
    "        j_e=sites['VENUS']['East']['j']\n",
    "        \n",
    "        a = filesu\n",
    "        b = filesv\n",
    "        c = filesu\n",
    "        d = filesv\n",
    "        \n",
    "    else:\n",
    "        files_Central=get_filenames_15(to,tf, 'central', path)\n",
    "        files_East=get_filenames_15(to,tf,'east', path)\n",
    "        \n",
    "        i_c = 1\n",
    "        i_e = 1\n",
    "        j_c = 1\n",
    "        j_e = 1\n",
    "        \n",
    "        a = files_Central\n",
    "        b = files_Central\n",
    "        c = files_East\n",
    "        d = files_East\n",
    "\n",
    "    u_u_c, time = analyze.combine_files(a, 'vozocrtx','None',[j_c-1, j_c], [i_c-1,i_c])\n",
    "    v_v_c, timec = analyze.combine_files(b, 'vomecrty','None',[j_c-1, j_c], [i_c-1,i_c])\n",
    "    time_c = tidetools.convert_to_seconds(timec)\n",
    "    dep_t_c = nc.Dataset(b[-1]).variables['depthv']\n",
    "\n",
    "    u_u_e, time = analyze.combine_files(c, 'vozocrtx','None',[j_e-1, j_e], [i_e-1,i_e])\n",
    "    v_v_e, timee = analyze.combine_files(d, 'vomecrty','None',[j_e-1, j_e], [i_e-1,i_e])\n",
    "    time_e = tidetools.convert_to_seconds(timee)\n",
    "    dep_t_e = nc.Dataset(d[-1]).variables['depthv']\n",
    "\n",
    "        \n",
    "    depth=[dep_t_c[:], dep_t_e[:]] \n",
    "    \n",
    "    u_u_0 = np.ma.masked_values(u_u_e, 0)\n",
    "    v_v_0 = np.ma.masked_values(v_v_e, 0)\n",
    "    u_u_0c = np.ma.masked_values(u_u_c, 0)\n",
    "    v_v_0c = np.ma.masked_values(v_v_c, 0)\n",
    "\n",
    "    u_c, v_c=research_VENUS.unstag_rot_gridded(u_u_0c, v_v_0c, 'Central')\n",
    "    u_e, v_e=research_VENUS.unstag_rot_gridded(u_u_0, v_v_0, 'East')\n",
    "    times=[time_c,time_e]\n",
    "    us=[u_c, u_e]\n",
    "    vs=[v_c, v_e]\n",
    "    i=np.arange(0,2)\n",
    "    \n",
    "    thesize=(40,2)\n",
    "    vM2amp = np.zeros(thesize); vM2pha = np.zeros(thesize)\n",
    "    vK1amp = np.zeros(thesize); vK1pha = np.zeros(thesize)\n",
    "    uM2amp = np.zeros(thesize); uM2pha = np.zeros(thesize)\n",
    "    uK1amp = np.zeros(thesize); uK1pha = np.zeros(thesize)\n",
    "\n",
    "    for i, u, time, v in zip(i, us, times, vs):\n",
    "        uM2amp[:,i], uM2pha[:,i], uK1amp[:,i], uK1pha[:,i] = tidetools.fittit(u, time)\n",
    "        vM2amp[:,i], vM2pha[:,i], vK1amp[:,i], vK1pha[:,i] = tidetools.fittit(v, time) \n",
    "        \n",
    "    CX, SX, CY, SY, ap, am, ep, em, major, minor, theta = tidetools.ellipse_params (uM2amp, uM2pha, vM2amp, vM2pha)\n",
    "    CX_k, SX_k, CY_k, SY_k, ap_k, am_k, ep_k, em_k, major_k, minor_k, theta_k = tidetools.ellipse_params (uK1amp, uK1pha, vK1amp, vK1pha)\n",
    "    return depth, major, minor, theta, major_k, minor_k, theta_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filenames_15(t_orig, t_final, station, model_path):\n",
    "    \"\"\"Returns a list with the filenames for all files over the\n",
    "    defined period of time and sorted in chronological order for \n",
    "    the gridded 15 minutes data.\n",
    "\n",
    "    :arg t_orig: The beginning of the date range of interest.\n",
    "    :type t_orig: datetime object\n",
    "\n",
    "    :arg t_final: The end of the date range of interest.\n",
    "    :type t_final: datetime object\n",
    "\n",
    "    :arg model_path: Defines the path used (eg. nowcast)\n",
    "    :type model_path: string\n",
    "\n",
    "    :returns: files, a list of filenames\n",
    "    \"\"\"\n",
    "\n",
    "    numdays = (t_final-t_orig).days\n",
    "    dates = [t_orig + datetime.timedelta(days=num)\n",
    "             for num in range(0, numdays+1)]\n",
    "    dates.sort()\n",
    "    \n",
    "    files = []\n",
    "    for i in dates:\n",
    "        sdt = i.strftime('%d%b%y').lower()\n",
    "        filename = (model_path+'{}/VENUS_{}_gridded.nc'.format(sdt, station))\n",
    "        files.append(filename)\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadparam_15(to, tf, path):\n",
    "    \"\"\" This function loads all the data between the start and the end date\n",
    "    that contains gridded quarter-hourly velocity netCDF4 files. Then it mask, unstaggers and \n",
    "    rotates the velocities by component about the VENUS nodes. Lastly it fits \n",
    "    the velcities and caculates the tidal ellipse parameters for that date range.**(Important not \n",
    "    to have a to < 2015-05-09 because the files do not exist before this date).**\n",
    "    \"\"\"\n",
    "    \n",
    "    files_Central=get_filenames_15(to,tf, 'central', path)\n",
    "    files_East=get_filenames_15(to,tf,'east', path)\n",
    "    \n",
    "    u_u_c, timer = analyze.combine_files(files_Central, 'vozocrtx','None',[0,1], [0,1])\n",
    "    v_v_c, time = analyze.combine_files(files_Central, 'vomecrty','None', [0,1], [0,1])\n",
    "    time_c = tidetools.convert_to_seconds(timer)\n",
    "    dep_t_c= nc.Dataset(files_Central[-1]).variables['depthv']\n",
    "\n",
    "    u_u_e, time = analyze.combine_files(files_East,'vozocrtx', 'None', [0,1], [0,1])\n",
    "    v_v_e, time = analyze.combine_files(files_East,'vomecrty', 'None',[0,1], [0,1])\n",
    "    time_e = tidetools.convert_to_seconds(timer)\n",
    "    dep_t_e = nc.Dataset(files_East[-1]).variables['depthv']\n",
    "    \n",
    "    depth=[dep_t_c[:], dep_t_e[:]] \n",
    "    \n",
    "    u_u_0 = np.ma.masked_values(u_u_e, 0)\n",
    "    v_v_0 = np.ma.masked_values(v_v_e, 0)\n",
    "    u_u_0c = np.ma.masked_values(u_u_c, 0)\n",
    "    v_v_0c = np.ma.masked_values(v_v_c, 0)\n",
    "\n",
    "    u_c, v_c=research_VENUS.unstag_rot_gridded(u_u_0c, v_v_0c, 'Central')\n",
    "    u_e, v_e=research_VENUS.unstag_rot_gridded(u_u_0, v_v_0, 'East')\n",
    "    times=[time_c,time_e]\n",
    "    us=[u_c, u_e]\n",
    "    vs=[v_c, v_e]\n",
    "    i=np.arange(0,2)\n",
    "\n",
    "    thesize=(40,2)\n",
    "    vM2amp = np.zeros(thesize); vM2pha = np.zeros(thesize)\n",
    "    vK1amp = np.zeros(thesize); vK1pha = np.zeros(thesize)\n",
    "    uM2amp = np.zeros(thesize); uM2pha = np.zeros(thesize)\n",
    "    uK1amp = np.zeros(thesize); uK1pha = np.zeros(thesize)\n",
    "\n",
    "    for i, u, time, v in zip(i, us, times, vs):\n",
    "        uM2amp[:,i], uM2pha[:,i], uK1amp[:,i], uK1pha[\n",
    "            :,i] = tidetools.fittit(u, time)\n",
    "        vM2amp[:,i], vM2pha[:,i], vK1amp[:,i], vK1pha[\n",
    "            :,i] = tidetools.fittit(v, time) \n",
    "\n",
    "    CX, SX, CY, SY, ap, am, ep, em, major, minor, theta = tidetools.ellipse_params (uM2amp, uM2pha, vM2amp, vM2pha)\n",
    "   \n",
    "    CX_k, SX_k, CY_k, SY_k, ap_k, am_k, ep_k, em_k, major_k, minor_k, theta_k = tidetools.ellipse_params (uK1amp, uK1pha, vK1amp, vK1pha)\n",
    "    return depth, major, minor, theta, major_k, minor_k, theta_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to save tidal parameters in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writetocsv(runname, depth, major, minor,theta, majork1, minork1, thetak1, station):\n",
    "    outfile = runname+'.csv'\n",
    "    \n",
    "    if station == 'Central':\n",
    "        k=0\n",
    "    else:\n",
    "        k=1\n",
    "    with open(outfile, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow([\n",
    "                'Depth', 'Major-Axis (M2)', 'Minor-Axis (M2)', 'Theta (M2)',\n",
    "                'Major-Axis (K1)', 'Minor-Axis (K1)', 'Theta (K1)'\n",
    "            ])\n",
    "        for i in np.arange(0,39):\n",
    "            writer.writerow([depth[k][i], major[i,k], minor[i,k], theta[i,k], majork1[i,k], minork1[i,k], thetak1[i,k]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###All the hourly data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not use data before November 26th 2014 for tidal ellipses, the model tides change this day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2014,11,26)\n",
    "tf=datetime.datetime(2015,6,8)\n",
    "freq = 'h'\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "depth, major, minor, theta, major_k, minor_k, theta_k= loadparam(to, tf, path)\n",
    "\n",
    "runname1 = '{}_{}_{}_Central'.format(t_o, t_f, freq)\n",
    "runname2 = '{}_{}_{}_East'.format(t_o, t_f, freq)\n",
    "\n",
    "writetocsv(runname1, depth, major, minor, theta, major_k, minor_k, theta_k, 'Central')\n",
    "writetocsv(runname2, depth, major, minor, theta, major_k, minor_k, theta_k, 'East')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###For all quarter-hourly values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2015,5,9)\n",
    "tf=datetime.datetime(2015,5,30)\n",
    "freq= 'h'\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "depth, major, minor, theta, major_k, minor_k, theta_k= loadparam(to, tf, path)\n",
    "runname1 = '{}_{}_{}_Central'.format(t_o, t_f, freq)\n",
    "runname2 = '{}_{}_{}_East'.format(t_o, t_f, freq)\n",
    "writetocsv(runname1, depth, major, minor, theta, major_k, minor_k, theta_k, 'Central')\n",
    "writetocsv(runname2, depth, major, minor, theta, major_k, minor_k, theta_k, 'East')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to open and read the columns you could use the lines below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df = pd.read_csv('20150601_20150608_h_Central.csv')\n",
    "depth = df.Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Quarter-Hourly Data\n",
    "##@ VENUS nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Month of May 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gridded data quarter hourly data only started to be recorded on May 9th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2015,5,9)\n",
    "tf=datetime.datetime(2015,5,30)\n",
    "freq=15\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "depth, major, minor, theta, major_k, minor_k, theta_k= loadparam(to, tf, path, '15')\n",
    "runname1 = '{}_{}_{}_Central'.format(t_o, t_f, freq)\n",
    "runname2 = '{}_{}_{}_East'.format(t_o, t_f, freq)\n",
    "\n",
    "writetocsv(runname1, depth, major, minor, theta, major_k, minor_k, theta_k, 'Central')\n",
    "writetocsv(runname2, depth, major, minor, theta, major_k, minor_k, theta_k, 'East')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
