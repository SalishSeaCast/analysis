{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to save the tidal parameters calculated from the model output to a csv file in order to avoid having to load all the files run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.patches import Ellipse\n",
    "import numpy as np\n",
    "from IPython.display import display, Math, Latex\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import netCDF4 as nc\n",
    "from scipy.optimize import curve_fit\n",
    "from salishsea_tools import (viz_tools,tidetools, nc_tools)\n",
    "from salishsea_tools.nowcast import (research_VENUS, analyze)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hourly Data\n",
    "##@ VENUS nodes\n",
    "The functions below will facilitate loading the hourly data and writting the tidal parameters to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadparam(to, tf, path, freq='h', depav='None'):\n",
    "    \"\"\" This function loads all the data between the start and the end date\n",
    "    that contains hourly velocity netCDF4 files. Then it mask, unstaggers and \n",
    "    rotates the velocities by component about the VENUS nodes. Lastly it fits \n",
    "    the velcities and caculates the tidal ellipse parameters for that date range.\n",
    "    \n",
    "    depth : vector [dmin, dmax]\n",
    "    \"\"\"\n",
    "    if freq=='h':\n",
    "        filesu = analyze.get_filenames(to,tf, '1h', 'grid_U', path)\n",
    "        filesv=analyze.get_filenames(to,tf,'1h', 'grid_V', path)\n",
    "\n",
    "        sites=research_VENUS.SITES\n",
    "        i_c=sites['VENUS']['Central']['i']\n",
    "        i_e=sites['VENUS']['East']['i']\n",
    "        j_c=sites['VENUS']['Central']['j']\n",
    "        j_e=sites['VENUS']['East']['j']\n",
    "        \n",
    "        a = filesu\n",
    "        b = filesv\n",
    "        c = filesu\n",
    "        d = filesv\n",
    "        \n",
    "    else:\n",
    "        files_Central=analyze.get_filenames_15(to,tf, 'central', path)\n",
    "        files_East=analyze.get_filenames_15(to,tf,'east', path)\n",
    "        \n",
    "        i_c = 1\n",
    "        i_e = 1\n",
    "        j_c = 1\n",
    "        j_e = 1\n",
    "        \n",
    "        a = files_Central\n",
    "        b = files_Central\n",
    "        c = files_East\n",
    "        d = files_East\n",
    "\n",
    "    u_u_c, time = analyze.combine_files(a, 'vozocrtx','None',[j_c-1, j_c], [i_c-1,i_c])\n",
    "    v_v_c, timec = analyze.combine_files(b, 'vomecrty','None',[j_c-1, j_c], [i_c-1,i_c])\n",
    "    time_c = tidetools.convert_to_seconds(timec)\n",
    "    dep_t_c = nc.Dataset(b[-1]).variables['depthv']\n",
    "\n",
    "    u_u_e, time = analyze.combine_files(c, 'vozocrtx','None',[j_e-1, j_e], [i_e-1,i_e])\n",
    "    v_v_e, timee = analyze.combine_files(d, 'vomecrty','None',[j_e-1, j_e], [i_e-1,i_e])\n",
    "    time_e = tidetools.convert_to_seconds(timee)\n",
    "    dep_t_e = nc.Dataset(d[-1]).variables['depthv']\n",
    "\n",
    "        \n",
    "    depth=[dep_t_c[:], dep_t_e[:]] \n",
    "    \n",
    "    u_u_0 = np.ma.masked_values(u_u_e, 0)\n",
    "    v_v_0 = np.ma.masked_values(v_v_e, 0)\n",
    "    u_u_0c = np.ma.masked_values(u_u_c, 0)\n",
    "    v_v_0c = np.ma.masked_values(v_v_c, 0)\n",
    "\n",
    "    u_c, v_c=research_VENUS.unstag_rot_gridded(u_u_0c, v_v_0c, 'Central')\n",
    "    u_e, v_e=research_VENUS.unstag_rot_gridded(u_u_0, v_v_0, 'East')\n",
    "\n",
    "    \n",
    "    \n",
    "    if depav == 'None':\n",
    "        us=[u_c, u_e]\n",
    "        vs=[v_c, v_e]   \n",
    "        thesize=(40,2)\n",
    "        \n",
    "    else: \n",
    "        jc = np.where(np.logical_and( depth[0] > depav[0], depth[0] < depav[1]))\n",
    "        je = np.where(np.logical_and( depth[1] > depav[2], depth[1] < depav[3]))\n",
    "        \n",
    "        u_c_slice = u_c[:,jc[0]]\n",
    "        v_c_slice = v_c[:,jc[0]]\n",
    "        u_e_slice = u_e[:,je[0]]\n",
    "        v_e_slice = v_e[:,je[0]]\n",
    "        \n",
    "        uc_av = analyze.depth_average(u_c_slice,depth[0][jc],1)\n",
    "        vc_av = analyze.depth_average(v_c_slice,depth[0][jc],1)\n",
    "        ue_av = analyze.depth_average(u_e_slice,depth[1][je],1)\n",
    "        ve_av = analyze.depth_average(v_e_slice,depth[1][je],1)\n",
    "        \n",
    "        thesize = (1,2)\n",
    "        us=[uc_av, ue_av]\n",
    "        vs=[vc_av, ve_av] \n",
    "        \n",
    "    times=[time_c,time_e]    \n",
    "    i=np.arange(0,2)\n",
    "\n",
    "    vM2amp = np.zeros(thesize); vM2pha = np.zeros(thesize)\n",
    "    vK1amp = np.zeros(thesize); vK1pha = np.zeros(thesize)\n",
    "    uM2amp = np.zeros(thesize); uM2pha = np.zeros(thesize)\n",
    "    uK1amp = np.zeros(thesize); uK1pha = np.zeros(thesize) \n",
    "    for i, u, time, v in zip(i, us, times, vs):\n",
    "        uM2amp[:,i], uM2pha[:,i], uK1amp[:,i], uK1pha[:,i] = tidetools.fittit(u, time)\n",
    "        vM2amp[:,i], vM2pha[:,i], vK1amp[:,i], vK1pha[:,i] = tidetools.fittit(v, time)\n",
    "\n",
    "    CX, SX, CY, SY, ap, am, ep, em, major, minor, theta, phase = tidetools.ellipse_params (uM2amp, uM2pha, vM2amp, vM2pha)\n",
    "    CX_k, SX_k, CY_k, SY_k, ap_k, am_k, ep_k, em_k, major_k, minor_k, theta_k, phase_k = tidetools.ellipse_params (uK1amp, uK1pha, vK1amp, vK1pha)\n",
    "\n",
    "    return depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fb7da59ae50c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/data/dlatorne/MEOPAR/SalishSea/nowcast/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mto\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2015\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2015\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'h'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2015,6,6)\n",
    "tf=datetime.datetime(2015,6,8)\n",
    "freq = 'h'\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= tidetools.loadparam_all(to, tf, path, depav=[35,300,20,160])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filenames_15(t_orig, t_final, station, model_path):\n",
    "    \"\"\"Returns a list with the filenames for all files over the\n",
    "    defined period of time and sorted in chronological order for \n",
    "    the gridded 15 minutes data.\n",
    "\n",
    "    :arg t_orig: The beginning of the date range of interest.\n",
    "    :type t_orig: datetime object\n",
    "\n",
    "    :arg t_final: The end of the date range of interest.\n",
    "    :type t_final: datetime object\n",
    "\n",
    "    :arg model_path: Defines the path used (eg. nowcast)\n",
    "    :type model_path: string\n",
    "\n",
    "    :returns: files, a list of filenames\n",
    "    \"\"\"\n",
    "\n",
    "    numdays = (t_final-t_orig).days\n",
    "    dates = [t_orig + datetime.timedelta(days=num)\n",
    "             for num in range(0, numdays+1)]\n",
    "    dates.sort()\n",
    "    \n",
    "    files = []\n",
    "    for i in dates:\n",
    "        sdt = i.strftime('%d%b%y').lower()\n",
    "        filename = (model_path+'{}/VENUS_{}_gridded.nc'.format(sdt, station))\n",
    "        files.append(filename)\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadparam_15(to, tf, path):\n",
    "    \"\"\" This function loads all the data between the start and the end date\n",
    "    that contains gridded quarter-hourly velocity netCDF4 files. Then it mask, unstaggers and \n",
    "    rotates the velocities by component about the VENUS nodes. Lastly it fits \n",
    "    the velcities and caculates the tidal ellipse parameters for that date range.**(Important not \n",
    "    to have a to < 2015-05-09 because the files do not exist before this date).**\n",
    "    \"\"\"\n",
    "    \n",
    "    files_Central=analyze.get_filenames_15(to,tf, 'central', path)\n",
    "    files_East=analyze.get_filenames_15(to,tf,'east', path)\n",
    "    \n",
    "    u_u_c, timer = analyze.combine_files(files_Central, 'vozocrtx','None',[0,1], [0,1])\n",
    "    v_v_c, time = analyze.combine_files(files_Central, 'vomecrty','None', [0,1], [0,1])\n",
    "    time_c = tidetools.convert_to_seconds(timer)\n",
    "    dep_t_c= nc.Dataset(files_Central[-1]).variables['depthv']\n",
    "\n",
    "    u_u_e, time = analyze.combine_files(files_East,'vozocrtx', 'None', [0,1], [0,1])\n",
    "    v_v_e, time = analyze.combine_files(files_East,'vomecrty', 'None',[0,1], [0,1])\n",
    "    time_e = tidetools.convert_to_seconds(timer)\n",
    "    dep_t_e = nc.Dataset(files_East[-1]).variables['depthv']\n",
    "    \n",
    "    depth=[dep_t_c[:], dep_t_e[:]] \n",
    "    \n",
    "    u_u_0 = np.ma.masked_values(u_u_e, 0)\n",
    "    v_v_0 = np.ma.masked_values(v_v_e, 0)\n",
    "    u_u_0c = np.ma.masked_values(u_u_c, 0)\n",
    "    v_v_0c = np.ma.masked_values(v_v_c, 0)\n",
    "\n",
    "    u_c, v_c=research_VENUS.unstag_rot_gridded(u_u_0c, v_v_0c, 'Central')\n",
    "    u_e, v_e=research_VENUS.unstag_rot_gridded(u_u_0, v_v_0, 'East')\n",
    "    times=[time_c,time_e]\n",
    "    us=[u_c, u_e]\n",
    "    vs=[v_c, v_e]\n",
    "    i=np.arange(0,2)\n",
    "\n",
    "    thesize=(40,2)\n",
    "    vM2amp = np.zeros(thesize); vM2pha = np.zeros(thesize)\n",
    "    vK1amp = np.zeros(thesize); vK1pha = np.zeros(thesize)\n",
    "    uM2amp = np.zeros(thesize); uM2pha = np.zeros(thesize)\n",
    "    uK1amp = np.zeros(thesize); uK1pha = np.zeros(thesize)\n",
    "\n",
    "    for i, u, time, v in zip(i, us, times, vs):\n",
    "        uM2amp[:,i], uM2pha[:,i], uK1amp[:,i], uK1pha[\n",
    "            :,i] = tidetools.fittit(u, time)\n",
    "        vM2amp[:,i], vM2pha[:,i], vK1amp[:,i], vK1pha[\n",
    "            :,i] = tidetools.fittit(v, time) \n",
    "\n",
    "    CX, SX, CY, SY, ap, am, ep, em, major, minor, theta = tidetools.ellipse_params (uM2amp, uM2pha, vM2amp, vM2pha)\n",
    "   \n",
    "    CX_k, SX_k, CY_k, SY_k, ap_k, am_k, ep_k, em_k, major_k, minor_k, theta_k = tidetools.ellipse_params (uK1amp, uK1pha, vK1amp, vK1pha)\n",
    "    return depth, major, minor, theta, major_k, minor_k, theta_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to save tidal parameters in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writetocsv(runname, depth, major, minor,theta, phase, majork1, minork1, thetak1, phasek1, station):\n",
    "    outfile = runname+'.csv'\n",
    "    \n",
    "    if station == 'Central':\n",
    "        k=0\n",
    "    else:\n",
    "        k=1\n",
    "    with open(outfile, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        if major.shape[0] == 1:\n",
    "            writer.writerow([\n",
    "                'Major(M2)', 'Minor(M2)', 'Inc(M2)','Pha(M2)'\n",
    "                'Major(K1)', 'Minor(K1)', 'Inc(K1)', 'Pha(K1)'\n",
    "            ])\n",
    "            writer.writerow([major[0,k], minor[0,k], theta[0,k], phase[0,k], majork1[0,k], minork1[0,k], thetak1[0,k], phasek1[0,k]])\n",
    "        else: \n",
    "            writer.writerow([\n",
    "                'Depth', 'Major(M2)', 'Minor(M2)', 'Inc(M2)','Pha(M2)'\n",
    "                'Major(K1)', 'Minor(K1)', 'Inc(K1)', 'Pha(K1)'\n",
    "            ])\n",
    "            for i in np.arange(0,39):\n",
    "                writer.writerow([depth[k][i], major[i,k], minor[i,k], theta[i,k], phase[i,k], majork1[i,k], minork1[i,k], thetak1[i,k], phasek1[i,k]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###All the hourly data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not use data before November 26th 2014 for tidal ellipses, the model tides change this day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-c816ecc7318b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mt_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%d%b%y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdepav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmajor_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadparam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepav\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mrunname1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{}_{}_{}_Central_depav'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_o\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-319671fa6de2>\u001b[0m in \u001b[0;36mloadparam\u001b[1;34m(to, tf, path, freq, depav)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles_East\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mu_u_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vozocrtx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'None'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj_c\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi_c\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mv_v_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vomecrty'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'None'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj_c\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi_c\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mtime_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtidetools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/ocean/mdunn/MEOPAR/tools/SalishSeaTools/salishsea_tools/nowcast/analyze.pyc\u001b[0m in \u001b[0;36mcombine_files\u001b[1;34m(files, var, depth, jss, iss)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'None'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m             \u001b[0mvar_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mvar_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mnetCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4.Variable.__getitem__ (netCDF4.c:37286)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnetCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4.Variable._get (netCDF4.c:44834)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnetCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4.Variable.dimensions.__get__ (netCDF4.c:33606)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnetCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4.Variable._getdims (netCDF4.c:33059)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/mdunn/anaconda/lib/python2.7/encodings/utf_8.pyc\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mencode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutf_8_encode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2014,11,26)\n",
    "tf=datetime.datetime(2015,6,18)\n",
    "freq = '15'\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "depav = [35,300,20,160]\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k = loadparam(to, tf, path, depav=depav)\n",
    "\n",
    "runname1 = '{}_{}_{}_Central_depav'.format(t_o, t_f, freq)\n",
    "runname2 = '{}_{}_{}_East_depav'.format(t_o, t_f, freq)\n",
    "\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'Central')\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'East')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###For all quarter-hourly values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2015,5,9)\n",
    "tf=datetime.datetime(2015,5,30)\n",
    "freq= 'h'\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "\n",
    "depth, major, minor, theta, major_k, minor_k, theta_k= loadparam(to, tf, path)\n",
    "runname1 = '{}_{}_{}_Central'.format(t_o, t_f, freq)\n",
    "runname2 = '{}_{}_{}_East'.format(t_o, t_f, freq)\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'Central')\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'East')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to open and read the columns you could use the lines below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df = pd.read_csv('20150601_20150608_h_Central.csv')\n",
    "depth = df.Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Quarter-Hourly Data\n",
    "##@ VENUS nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Month of May 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gridded data quarter hourly data only started to be recorded on May 9th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/data/dlatorne/MEOPAR/SalishSea/nowcast/'\n",
    "\n",
    "to=datetime.datetime(2015,6,16)\n",
    "tf=datetime.datetime(2015,6,18)\n",
    "freq=15\n",
    "\n",
    "t_o = to.strftime('%d%b%y').lower()\n",
    "t_f = tf.strftime('%d%b%y').lower()\n",
    "depav = [35,300,20,160]\n",
    "\n",
    "depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k= loadparam(to, tf, path, '15')\n",
    "runname1 = '{}_{}_{}_Central'.format(t_o, t_f, freq)\n",
    "runname2 = '{}_{}_{}_East'.format(t_o, t_f, freq)\n",
    "\n",
    "writetocsv(runname1, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'Central')\n",
    "writetocsv(runname2, depth, major, minor, theta, phase, major_k, minor_k, theta_k, phase_k, 'East')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
